{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31e448a-2aff-40fd-b721-b4f1baa07691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup\n",
    "# ! sudo apt install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxrender1 libxext6\n",
    "# ! pip install open-iris==1.0.0 faiss-cpu seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765202e0-2135-4dce-a4d2-fc0d3fe39f0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37203805-61d2-4963-bd9e-dd32f226ef24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100b0cd0-fc4b-41de-a454-8f4d7b8c40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "import igraph as ig\n",
    "import pickle\n",
    "import iris\n",
    "import scipy\n",
    "import psutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import threading\n",
    "from itertools import combinations, product\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032dbdcc-dc6b-424d-ab8c-913f35290510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname('/Users/odedgoffer/Documents/GitHub/hnsw-demo/analysis_notebooks/'), '..'))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3699cf2a-f287-40fa-9437-ec38eda0fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnsw\n",
    "from iris.io.dataclasses import IrisTemplate\n",
    "from iris_integration import (\n",
    "    iris_with_noise,\n",
    "    irisint_make_query as make_query,\n",
    "    irisint_query_to_vector as query_to_vector,\n",
    "    irisint_distance as distance,\n",
    ")\n",
    "from iris_pairwise_min_dist_calculation import get_pairwise_min_dist_across_rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3955219b-b483-41e5-9f18-8f87facafccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp, ttest_ind\n",
    "from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4c645f-001c-46a7-82ed-48b5e28b771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 6 # Fit to CPU\n",
    "DIM = (2, 32, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a87c9-389d-4af7-8e91-e73678ed0146",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f3160b-b577-40da-a6af-9940a8c958b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update_time = time.time()\n",
    "def print_progress(msg, delay=1, force_print=False):\n",
    "    global last_update_time\n",
    "    if (time.time() - last_update_time > delay) or force_print:\n",
    "        sys.stdout.write('\\r' + ' ' * (shutil.get_terminal_size().columns - 1))\n",
    "        sys.stdout.write(f\"\\r{msg}\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        last_update_time = time.time()\n",
    "\n",
    "def save_pickle(obj, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    # print(f\"Object successfully saved to {filename}\")\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        obj = pickle.load(file)\n",
    "    # print(f\"Object successfully loaded from {filename}\")\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c680e91b-9672-4dd7-b93d-305dbb7a27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boolean_iris(matrix, title=''):\n",
    "    plt.imshow(matrix, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9489853f-1160-4379-9c75-57414d926109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_scaled_string(n):\n",
    "    suffixes = ['', 'K', 'M', 'B', 'T']\n",
    "    idx = max(0, min(len(suffixes) - 1, int((len(str(abs(n))) - 1) / 3)))\n",
    "    scaled = n / (1000 ** idx)\n",
    "    return f\"{scaled:.1f}{suffixes[idx]}\" if scaled % 1 else f\"{int(scaled)}{suffixes[idx]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162f8ea-4648-4370-92fd-1f3478f6138f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0badda9-84e3-4283-80b9-d8dfb51a2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_partial_file(filename, num_bits):\n",
    "    num_bytes = (num_bits + 7) // 8  # Ensure we round up if num_bits isn't a multiple of 8\n",
    "    with open(filename, 'rb') as f:\n",
    "        chunk = f.read(num_bytes)\n",
    "    return np.frombuffer(chunk, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2342bab4-e456-4757-858f-9471313f2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_reshape_masks(filename, num_masks, DIM=DIM):\n",
    "    flattened_data = np.unpackbits(read_partial_file(filename, ((DIM[1]//2) * DIM[2]) * num_masks))\n",
    "    boolean_arrays = flattened_data.reshape((num_masks, DIM[1]//2, DIM[2]))\n",
    "    vertically_stacked = np.tile(boolean_arrays, (1, 2, 1))\n",
    "    duplicated_arrays = np.repeat(vertically_stacked[:, np.newaxis, :, :], DIM[0], axis=1)\n",
    "    return duplicated_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614f337b-cdc2-4ef5-968b-754228da81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_reshape_irises(path_low, path_high, num_samples, DIM=DIM):\n",
    "    low_high_lst = [\n",
    "        np.unpackbits(\n",
    "            read_partial_file(path, (reduce(mul, DIM[1:]) * num_samples)), bitorder=\"little\"\n",
    "        ).reshape(num_samples, *DIM[1:]) for path in [path_low, path_high]\n",
    "    ]\n",
    "    return np.concatenate(low_high_lst, axis=1).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7759adc-0a87-4986-befa-de555ae2ea55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test Functions and DB Buildup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beebdb36-f7ed-4f3e-9007-95780ef33cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db(db, iris_df, db_size):\n",
    "    db_current_size = db.get_stats()['db_size']\n",
    "    assert (db_size - db_current_size) > 0\n",
    "    \n",
    "    new_irises = iris_df.loc[range(db_current_size, db_size), 'Template']\n",
    "    for i, iris in enumerate(new_irises):\n",
    "        print_progress(f'Currently building {int_to_scaled_string(db_size)} Data-base. Insertion progress: {(i+1)/len(new_irises):.2%}')\n",
    "        db.insert(make_query(iris))\n",
    "    iris_df.loc[range(db_current_size, db_size), 'Inserted'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4683a45-580c-486c-bc82-d8393015b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_array_to_iris_df(iris_array, mask_array):\n",
    "    def create_iris_template(matrix, mask):\n",
    "        return IrisTemplate(\n",
    "            iris_codes=matrix,\n",
    "            mask_codes=mask, \n",
    "            # iris_code_version=\"v3.0\" # Doesn't work on open-iris==1.0.0\n",
    "        )\n",
    "    iris_templates = Parallel(n_jobs=n_jobs)(delayed(create_iris_template)(list(iris), list(mask)) for iris, mask in zip(iris_array, mask_array))\n",
    "    return pd.DataFrame({'Template': iris_templates}).assign(Inserted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b86cf5c-b997-414f-a59f-1b35e986f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(db, idx, iris, noise, efSearch, K):\n",
    "    noisy_query = make_query(iris_with_noise(iris, noise_level=noise))\n",
    "    res = db.search(noisy_query, K, ef=efSearch)\n",
    "    return any(idx == tup[1] for tup in res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d6f7a3-2119-4573-9674-1d843a0629c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_diameter(db_size, M):\n",
    "    return np.log(db_size) / np.log((2*M)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198d877-10bd-4d79-9703-36c27e064069",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712eda6-b866-4f08-af01-d74343f37f6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f03f6a1-bd95-4f90-8578-47002f867e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_size = 2**22\n",
    "max_tested_db_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e6f68de-3556-42bb-b50f-ef7915b31af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_masks = f'synthetic_data/{int_to_scaled_string(synthetic_data_size)}_mask_arrays.dat'\n",
    "path_iris_low = 'synthetic_data/2_23_voter_arrays_90k_b090.dat'\n",
    "path_iris_high = 'synthetic_data/2_23_voter_arrays_14k_b010.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905d802-1a21-4a60-a039-c86f2cba21bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "593e55bf-6f71-4362-a412-83d76e8b1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_masks = load_and_reshape_masks(path_masks, max_tested_db_size).astype(bool)\n",
    "loaded_irises = load_and_reshape_irises(path_iris_low, path_iris_high, max_tested_db_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e653a08-4e76-4ce5-8ce4-0eeb220018df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reassuring stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "890b40b4-2d15-408d-986a-772b9436dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly loaded 100K masks and irises\n"
     ]
    }
   ],
   "source": [
    "assert len(loaded_masks) == max_tested_db_size\n",
    "assert len(loaded_irises) == max_tested_db_size\n",
    "print(f'Successfuly loaded {int_to_scaled_string(max_tested_db_size)} masks and irises')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff19d2-cd62-4dcb-9111-ebc31548d524",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Graph analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f99e9-c36b-46bf-ad94-5526dbf1c678",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c5ff548-0fb3-4ef7-b91d-3394c999a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 64\n",
    "db_size_range = np.arange(10000, 100001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "499855be-c93e-469a-b16d-f3b9f0210b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert db_size_range.max() <= max_tested_db_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a19d3b-5cca-498c-91db-1b948fee995c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DB and graph Build up and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d03cf859-c6db-42e7-8b4a-b660121f5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = numpy_array_to_iris_df(loaded_irises.reshape(max_tested_db_size, *DIM), loaded_masks)\n",
    "db = hnsw.HNSW(\n",
    "    M=M, \n",
    "    efConstruction=M, \n",
    "    m_L=1/np.log(M**6), \n",
    "    distance_func=distance, \n",
    "    query_to_vector_func=query_to_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44c041f9-747b-442a-9d21-ec14a6e51827",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Betweenness Centrality of Data-base size 10K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 20K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 30K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 40K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 50K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 60K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 70K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 80K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 90K                       Object successfully saved to betweenness_centrality_dict.pkl\n",
      "Calculating Betweenness Centrality of Data-base size 100K                      Object successfully saved to betweenness_centrality_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "betweenness_centrality_dict = dict()\n",
    "for db_size in db_size_range:\n",
    "    update_db(db, iris_df, db_size)\n",
    "    print_progress(f'Calculating Betweenness Centrality of Data-base size {int_to_scaled_string(db_size)}', force_print=True)\n",
    "    \n",
    "    layer_0_graph = ig.Graph()\n",
    "    layer_0_graph.add_vertices(list(range(db_size)))\n",
    "    edges_to_add = list(\n",
    "        set(\n",
    "            (min(source, target), max(source, target)) for source, target_lst in db.layers[0].items() \n",
    "            for _, target in target_lst\n",
    "        )\n",
    "    )\n",
    "    layer_0_graph.add_edges(edges_to_add)\n",
    "    \n",
    "    max_betweenness = (db_size - 1) * (db_size - 2) / 2\n",
    "    betweenness_centrality_dict[db_size] = {\n",
    "        'betweenness_centrality':pd.Series(layer_0_graph.betweenness(directed=False)) / max_betweenness,\n",
    "        'entry_point':db.entry_point\n",
    "    }\n",
    "    save_pickle(betweenness_centrality_dict, 'betweenness_centrality_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355a9d6-d218-47c2-bd56-489588e730a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality_dict = load_pickle('betweenness_centrality_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35fba9-7cdf-4d35-b7f1-7829bdeae75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for db_size, curr_betweenness_centrality_dict in betweenness_centrality_dict.items():\n",
    "    betweenness_values = pd.Series(curr_betweenness_centrality_dict['betweenness_centrality'])\n",
    "    entry_points = curr_betweenness_centrality_dict['entry_point']\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(betweenness_values.rename('Betweenness Centrality'), stat='probability', color='#34675C')\n",
    "    for entry_point in entry_points:\n",
    "        quantile = np.searchsorted(np.sort(betweenness_values), betweenness_values[entry_point], side='right') / len(betweenness_values)\n",
    "        plt.axvline(x=betweenness_values[entry_point], color='#F26800')\n",
    "        plt.text(betweenness_values[entry_point], plt.gca().get_ylim()[1] * 1.05, f'{1-quantile:.2%}', \n",
    "                 color='#F26800', ha='center', va='top', fontsize=10, fontweight='bold')\n",
    "    plt.title(f'Betweenness Centrality Distribution\\nData-base size {int_to_scaled_string(db_size)}', fontsize=15, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376d79b-bab8-4ff6-8d12-cc453975677c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41efea66-d557-42dd-a91d-b86f5c63a8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77bc78-5481-4e52-acba-6061b1fe1fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3984668-3cc5-4b54-9f81-4cb458e6d335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6417a8-c46b-4fb9-b3c8-72794ac73425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
