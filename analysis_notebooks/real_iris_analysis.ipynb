{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e448a-2aff-40fd-b721-b4f1baa07691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup\n",
    "# ! sudo apt install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxrender1 libxext6\n",
    "# ! pip install open-iris==1.0.0 faiss-cpu seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765202e0-2135-4dce-a4d2-fc0d3fe39f0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b0cd0-fc4b-41de-a454-8f4d7b8c40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "import iris\n",
    "import scipy\n",
    "import psutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import threading\n",
    "from itertools import combinations, product\n",
    "from functools import reduce\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955219b-b483-41e5-9f18-8f87facafccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c645f-001c-46a7-82ed-48b5e28b771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 6 # Fit to CPU\n",
    "DIM = (2, 32, 200)\n",
    "X, Y = DIM [1:]\n",
    "MAX_ROT = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b569f45-be94-4021-b194-a80ad4a554ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73112ef-4223-4a37-a808-bf7c7ee9e2f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Real Irises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4efc2-76bd-4842-aa8b-c9f290deed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (16, 200)\n",
    "# DEV = \"-dev\" # Access test data.\n",
    "DEV = \"\" # Access real data.\n",
    "print(\"Working on simulated data\" if DEV else \"Working on real data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b35c9-ffbb-46d6-a0ce-a49df5b3693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'wld-inversed-data-sharing' + DEV\n",
    "role_arn = 'arn:aws:iam::387760840988:role/worldcoin-data' + DEV\n",
    "metadata_path = 'metadata.csv'\n",
    "\n",
    "def memoize(func):\n",
    "    cache = {}\n",
    "    def memoized_func(*args):\n",
    "        if args in cache:\n",
    "            return cache[args]\n",
    "        result = func(*args)\n",
    "        cache[args] = result\n",
    "        return result\n",
    "    return memoized_func\n",
    "\n",
    "def assume_role(role_arn, session_name=\"S3ReadSession\"):\n",
    "    sts_client = boto3.client('sts')\n",
    "    assumed_role_object = sts_client.assume_role(\n",
    "        RoleArn=role_arn,\n",
    "        RoleSessionName=session_name\n",
    "    )\n",
    "    credentials = assumed_role_object['Credentials']\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=credentials['AccessKeyId'],\n",
    "        aws_secret_access_key=credentials['SecretAccessKey'],\n",
    "        aws_session_token=credentials['SessionToken']\n",
    "    )\n",
    "    return s3\n",
    "\n",
    "# Assume the role and get credentials\n",
    "s3 = assume_role(role_arn, \"S3ReadSession\")\n",
    "\n",
    "def read_s3_file(bucket_name, file_key):\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    return BytesIO(obj['Body'].read())\n",
    "\n",
    "@memoize\n",
    "def load_response(image_id):\n",
    "    \" Return IrisFilterResponse \"\n",
    "    path = \"iris_filter_responses/\" + image_id + \".pickle\"\n",
    "    try:\n",
    "        pkl_file = read_s3_file(bucket_name, path)\n",
    "        return pickle.load(pkl_file)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "\n",
    "@memoize\n",
    "def load_template(image_id):\n",
    "    \" Return IrisTemplate \"\n",
    "    path = \"iris_templates/\" + image_id + \".pickle\"\n",
    "    try:\n",
    "        pkl_file = read_s3_file(bucket_name, path)\n",
    "        return pickle.load(pkl_file)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "meta = pd.read_csv(read_s3_file(bucket_name, metadata_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc3653-a323-4e67-8194-8851206b6e7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Synthetic Irises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cff73-5e46-44de-9646-6bb81d9aae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_synthetic_iris(method, num_samples, path='compressed_iris_matrices'):\n",
    "    # Load data and randomly select num_samples samples\n",
    "    loaded_data = np.load(f'{path}_{method}.npz')['data']\n",
    "    assert loaded_data.shape[0] >= num_samples, f\"Requested {num_samples} samples, but only {loaded_data.shape[0]} available.\"\n",
    "    indices = np.random.choice(loaded_data.shape[0], num_samples, replace=False)\n",
    "    return loaded_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fbc5a-ce07-40b0-8b88-dbe37df54ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "for method in ['gaussian', 'voter', 'voter_gaussian']:\n",
    "    data_dict[method] = load_synthetic_iris(method, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20761b65-4529-4891-883e-6123ad8311d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_voter_model_rust_implementation(path, total_num_samples, num_samples=None):\n",
    "    num_samples = num_samples if num_samples else total_num_samples\n",
    "    assert num_samples <= total_num_samples\n",
    "    data = np.fromfile(path, dtype=np.uint8)\n",
    "    return (\n",
    "        np.unpackbits(data, bitorder=\"little\")\n",
    "        .reshape(total_num_samples, 32, 200)\n",
    "        [np.random.choice(total_num_samples, size=num_samples, replace=False)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ac4d4-0637-4706-ab96-f88e7a216d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bryan_low_data = import_voter_model_rust_implementation('2M_voter_arrays_80k_b45.dat', 1000000, 1000)\n",
    "bryan_high_data = import_voter_model_rust_implementation('2M_voter_arrays_7k_b13.dat', 1000000, 1000)\n",
    "data_dict['voter_bryan'] = np.concatenate([bryan_low_data, bryan_high_data], axis=1).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547eb39-37d5-4f32-a86f-06d665df1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = pd.concat(\n",
    "    [pd.DataFrame({'iris_matrices':list(data), 'source':source}) for source, data in data_dict.items()], \n",
    "    ignore_index=True\n",
    ")\n",
    "synthetic_df['mask_matrices'] = [np.ones((reduce(mul, DIM[:2]), DIM[-1])).astype(bool)] * len(synthetic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc09308-9166-49fd-b18a-2c027e8ef553",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10bc6e-39fc-4a2b-8668-341e91016981",
   "metadata": {},
   "source": [
    "## Real Irises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e15b5-61e9-410f-a8ea-e4074aff34e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102a01b-68c2-4884-8c93-393012b3c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for iterators.\n",
    "def take(count, it):\n",
    "    \" Take at most `count` items from the iterator `it` \"\n",
    "    for x in it:\n",
    "        if count is not None:\n",
    "            if count <= 0:\n",
    "                break\n",
    "            count -= 1\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836e9f8-8be1-4a4b-bff2-325ebcc1a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matching pairs.\n",
    "def iter_matching_image_ids(meta, unique_subjects):\n",
    "    \" Iterate matching pairs in the form (subject_id, ir_image_id_0, ir_image_id_1). \"\n",
    "    subject_ids = meta[\"subject_id\"].unique()\n",
    "\n",
    "    for side in [0, 1]:\n",
    "        meta_side = meta[meta[\"biological_side\"] == side]\n",
    "\n",
    "        for subject in subject_ids:\n",
    "            signups = meta_side[meta_side[\"subject_id\"] == subject]\n",
    "            if len(signups) < 2:\n",
    "                continue\n",
    "\n",
    "            L = 2 if unique_subjects else len(signups)\n",
    "\n",
    "            for i in range(L - 1):\n",
    "                for j in range(i + 1, L):\n",
    "                    yield (f\"{subject}_side{side}\", signups[\"ir_image_id\"].iloc[i], signups[\"ir_image_id\"].iloc[j])\n",
    "\n",
    "def load_matching_image_ids(meta, unique_subjects):\n",
    "    \" Return matching pairs in the form (subject_id, ir_image_id_0, ir_image_id_1), shuffled. \"    \n",
    "    pair_image_ids = list(iter_matching_image_ids(meta, unique_subjects))\n",
    "    rng = np.random.default_rng(seed=12345)\n",
    "    rng.shuffle(pair_image_ids)\n",
    "    return pair_image_ids\n",
    "\n",
    "def iter_related_pairs(meta, unique_subjects):\n",
    "    \" Iterate matching pairs in the form (subject_id, response_0, response_1). \"\n",
    "    for (subject, img_i, img_j) in load_matching_image_ids(meta, unique_subjects):\n",
    "        res_i = load_response(img_i)\n",
    "        res_j = load_response(img_j)\n",
    "        if res_i and res_j:\n",
    "            yield (subject, res_i, res_j)\n",
    "\n",
    "def load_related_pairs(meta, count=None, unique_subjects=False):\n",
    "    \" Return matching pairs in the form (subject_id, response_0, response_1). \"\n",
    "    return list(take(count, iter_related_pairs(meta, unique_subjects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f43732-bac3-4ca6-aaed-b51a8e4ce670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking methodologies\n",
    "def fill_masked_with_random(bits, mask):\n",
    "    filler = np.random.randint(0, 2, size=bits.shape, dtype=bool)\n",
    "    filler &= not_(mask)\n",
    "    bits ^= filler\n",
    "\n",
    "def fill_masked_with_zeros(bits, mask):\n",
    "    bits &= mask\n",
    "\n",
    "# Techniques that do not support masking will work, although with a modified scale of distances.\n",
    "# The change in distance can be calculated from the size of the overlap of masks. Alternatively,\n",
    "# it can be estimated with the expected average of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2afeb3-e259-4351-b54d-1565ec28e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make encoders from parameters.\n",
    "def make_encoder(v_subsample=1, h_subsample=1, top=True, bottom=True, real=True, imag=True, mask_threshold=0.9, static_mask=None, mask_with_random=False):\n",
    "\n",
    "    res_indexes = (top and [0] or []) + (bottom and [1] or [])\n",
    "    assert res_indexes, \"require top, bottom, or both\"\n",
    "\n",
    "    quantizers = (real and [np.real] or []) + (imag and [np.imag] or [])\n",
    "    assert quantizers, \"require real, imag, or both\"\n",
    "    \n",
    "    def encode(response):\n",
    "        bit_parts = []\n",
    "        mask_parts = []\n",
    "        \n",
    "        for res_index in res_indexes:\n",
    "            for quantizer in quantizers:\n",
    "                res = response.iris_responses[res_index][::v_subsample, ::h_subsample]\n",
    "                bits = quantizer(res) > 0\n",
    "                mask = response.mask_responses[res_index][::v_subsample, ::h_subsample] >= mask_threshold\n",
    "\n",
    "                if mask_with_random:\n",
    "                    # Replace masked bits with random bits.\n",
    "                    fill_masked_with_random(bits, mask)\n",
    "                \n",
    "                if static_mask is not None:\n",
    "                    # Remove the bits not selected by the static mask.\n",
    "                    fill_masked_with_zeros(bits, static_mask[::v_subsample, ::h_subsample])\n",
    "                    # Treat non-selected bits as masked (False).\n",
    "                    mask &= static_mask[::v_subsample, ::h_subsample]\n",
    "                \n",
    "                bit_parts.append(bits)\n",
    "                mask_parts.append(mask)\n",
    "                assert mask.shape == bits.shape\n",
    "\n",
    "        return np.concatenate(bit_parts), np.concatenate(mask_parts)\n",
    "    \n",
    "    return encode\n",
    "\n",
    "def encode_pairs(pairs, encode_fn):\n",
    "    return [\n",
    "        (subject_id, encode_fn(response_a), encode_fn(response_b))\n",
    "        for subject_id, response_a, response_b in pairs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2986ed9-5e2c-4b63-b902-0c92523cddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances\n",
    "def masked_distance(x, x_mask, y, y_mask):\n",
    "    mask = x_mask & y_mask\n",
    "    hd = np.sum((x ^ y) & mask)\n",
    "    return hd / np.sum(mask)\n",
    "\n",
    "def masked_rotate(x, rotation):\n",
    "    return (\n",
    "        np.roll(x[0], rotation, axis=1),\n",
    "        np.roll(x[1], rotation, axis=1),\n",
    "    )\n",
    "\n",
    "def distance(x, y):\n",
    "    return masked_distance(x[0], x[1], y[0], y[1])\n",
    "\n",
    "def distance_raw(raw_x, raw_y):\n",
    "    return distance(encode_high(raw_x), encode_high(raw_y))\n",
    "\n",
    "def rotate_raw(raw_x, rotation):\n",
    "    iris_responses = [\n",
    "        np.roll(r, rotation, axis=1)\n",
    "        for r in raw_x.iris_responses\n",
    "    ]\n",
    "    mask_responses = [\n",
    "        np.roll(r, rotation, axis=1)\n",
    "        for r in raw_x.mask_responses\n",
    "    ]\n",
    "    return iris.IrisFilterResponse(iris_responses=iris_responses, mask_responses=mask_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5342022-6bd3-4cca-ad65-7c760ef584c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotations.\n",
    "def without_rotation(pairs, distance_fn, rotate_fn, max_rotation):\n",
    "    for subject_id, x, y in pairs:\n",
    "        distances = [\n",
    "            distance_fn(x, rotate_fn(y, rotation))\n",
    "            for rotation in range(-max_rotation, max_rotation+1)\n",
    "        ]\n",
    "        best_rotation = -max_rotation + np.argmin(distances)        \n",
    "        y_aligned = rotate_fn(y, best_rotation)\n",
    "        yield (subject_id, x, y_aligned)\n",
    "\n",
    "def remove_rotation(pairs, distance_fn=distance, rotate_fn=masked_rotate, max_rotation=15):\n",
    "    return list(without_rotation(pairs, distance_fn, rotate_fn, max_rotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76d8fb-86ad-4405-8bb9-123be0c7dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boolean_iris(matrix, title=''):\n",
    "    plt.imshow(matrix, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02024c46-22e8-406a-bcc5-d25fa048fb6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282e0ee-578e-41a3-869f-0d433508c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 min\n",
    "encode_high = make_encoder()\n",
    "related_pairs = load_related_pairs(meta, count=None, unique_subjects=False)\n",
    "related_pairs_norot = remove_rotation(related_pairs, distance_fn=distance_raw, rotate_fn=rotate_raw)\n",
    "related_pairs_high = encode_pairs(related_pairs_norot, encode_high)\n",
    "shape_high = related_pairs_high[0][1][0].shape\n",
    "print(f\"Finished loading {len(related_pairs_high)} pairs,\", \"High-res\", shape_high, np.prod(shape_high), \"bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3c245-431e-41e5-9b12-30018dd2088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_array = np.array(related_pairs_high, dtype=object)\n",
    "subject_ids = np.repeat(tuples_array[:, 0], 2)  # Repeat each subject_id twice\n",
    "flattened_result = [item for tup in tuples_array for item in tup[1:]]\n",
    "iris_matrices, mask_matrices = zip(*flattened_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91deb9-4e4a-4f80-be97-b0386068e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_iris_df = pd.DataFrame({\n",
    "    'subject_id': subject_ids,\n",
    "    'iris_matrices': iris_matrices,\n",
    "    'mask_matrices': mask_matrices\n",
    "})\n",
    "true_iris_df['side'] = true_iris_df['subject_id'].apply(lambda x: x[-1])\n",
    "true_iris_df['subject_id'] = true_iris_df['subject_id'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67897c5c-d9a4-40aa-b23f-cbd82deabf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "true_iris_df['iris_matrices_bytes'] = true_iris_df['iris_matrices'].apply(lambda matrix: matrix.tobytes())\n",
    "true_iris_df['mask_matrices_bytes'] = true_iris_df['mask_matrices'].apply(lambda matrix: matrix.tobytes())\n",
    "true_iris_df = (\n",
    "    true_iris_df\n",
    "    .drop_duplicates(subset=['subject_id', 'iris_matrices_bytes', 'mask_matrices_bytes'])\n",
    "    .drop(columns=['iris_matrices_bytes', 'mask_matrices_bytes'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(f'Final iris DataFrame contains {len(true_iris_df)} unique samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc16f2a-0925-4b06-a8af-68a5d27890b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Noise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8671c-86a2-4178-86d8-0b54ecd86b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_rotated_matrices(matrices, max_rotation):\n",
    "    return np.vstack([\n",
    "        np.roll(matrix, shift, axis=0).flatten()\n",
    "        for matrix, shift in product(matrices, range(-max_rotation, max_rotation + 1))\n",
    "    ])\n",
    "\n",
    "def get_pairwise_min_dist_across_rotations(iris_matrices, mask_matrices, max_rotation, lim_group_size=50):\n",
    "    if len(iris_matrices) > lim_group_size:\n",
    "        iris_matrices = iris_matrices.sample(lim_group_size)\n",
    "        mask_matrices = mask_matrices[iris_matrices.index]\n",
    "\n",
    "    # Create rotated matrices and masks\n",
    "    rotated_matrices = stack_rotated_matrices(iris_matrices, max_rotation)\n",
    "    rotated_masks = stack_rotated_matrices(mask_matrices, max_rotation)\n",
    "    \n",
    "    # Calculate pairwise Hamming distances considering only True values in the mask\n",
    "    valid_positions = np.expand_dims(rotated_masks, axis=1) & np.expand_dims(rotated_masks, axis=0)\n",
    "    differences = np.expand_dims(rotated_matrices, axis=1) != np.expand_dims(rotated_matrices, axis=0)\n",
    "    hamming_distances = np.sum(differences & valid_positions, axis=-1) / np.sum(valid_positions, axis=-1)\n",
    "    \n",
    "    # Mask self-comparisons with np.inf\n",
    "    matrix_indices = np.arange(len(iris_matrices)).repeat(2 * max_rotation + 1)\n",
    "    hamming_distances[matrix_indices[:, None] == matrix_indices[None, :]] = np.inf\n",
    "    \n",
    "    # Reshape and find minimum distances\n",
    "    reshaped_distances = hamming_distances.reshape(len(iris_matrices), 2 * max_rotation + 1, len(iris_matrices), 2 * max_rotation + 1)\n",
    "    min_distances_per_matrix = np.min(reshaped_distances, axis=(1, 3))\n",
    "\n",
    "    # Extract only the lower triangle (excluding the diagonal)\n",
    "    return min_distances_per_matrix[np.tril_indices(len(iris_matrices), k=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255080a7-4e0d-493f-b1d2-f754fdd589fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for (subject_id, side), group in true_iris_df.groupby(['subject_id', 'side']):\n",
    "    results.append(get_pairwise_min_dist_across_rotations(group['iris_matrices'], group['mask_matrices'], max_rotation=MAX_ROT))\n",
    "nearest_pairwise_dist_w_rotations = np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942209f1-d82a-4a0c-bcae-9bdc28d8805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "sns.histplot(nearest_pairwise_dist_w_rotations, stat='probability', bins=100, color='#BD2A2E')\n",
    "plt.title('Same Samples Distance Distribution (Noise)', fontsize=15, y=1.08)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6556cb6-ea26-4754-b26b-2359556bac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distribution(data, num_bins=100):\n",
    "    counts, bin_edges = np.histogram(data, bins=num_bins, density=True)\n",
    "    midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    probabilities = counts / np.sum(counts)\n",
    "    return midpoints, probabilities\n",
    "    \n",
    "def sample_from_distribution(midpoints, probabilities, sample_size=10):\n",
    "    return np.random.choice(midpoints, size=sample_size, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e3c73-09bb-4c5f-bd08-8767402e83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "midpoints, probabilities = calculate_distribution(nearest_pairwise_dist_w_rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d364f8-9948-49d7-a947-88f3c2d25cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_distribution(midpoints, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d185d15-782b-43be-8f3e-ba937fd1adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez_compressed('noise_distribution_bin_midpoints.npz', data=midpoints)\n",
    "# np.savez_compressed('noise_distribution_probability_distribution.npz', data=probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530917c7-3248-4cc5-b249-3364922724fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Short Mask Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c95c4-6f50-4d04-a4ba-fca9f2784776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_masks(mask_matrix):\n",
    "    # Adjust matrix to be built by 8 different masks\n",
    "    separated_matrix = mask_matrix.reshape(4, 16, 2, 100).transpose(2, 0, 1, 3)\n",
    "\n",
    "    # Calculate bottom row stats\n",
    "    inverted_last_rows = ~separated_matrix[:, :, -1, :]\n",
    "    mean_true_counts = inverted_last_rows.sum(axis=2).mean(axis=1) # Mean length\n",
    "    first_true_indices = np.where(\n",
    "        inverted_last_rows.any(axis=-1), np.argmax(inverted_last_rows, axis=-1), np.nan\n",
    "    )\n",
    "    last_true_indices = np.where(\n",
    "        inverted_last_rows.any(axis=-1), inverted_last_rows.shape[-1] - 1 - np.argmax(inverted_last_rows[:, :, ::-1], axis=-1), np.nan\n",
    "    )\n",
    "    mean_middle_indices = np.nanmean((first_true_indices + last_true_indices) / 2, axis=1) # Mean middle index\n",
    "\n",
    "    # Calculate longest column stats\n",
    "    true_counts = (~separated_matrix).sum(axis=2)\n",
    "    max_true_counts = np.max(true_counts, axis=2)\n",
    "    mean_max_true_counts = max_true_counts.mean(axis=1)\n",
    "    return (*mean_true_counts, *mean_middle_indices, *mean_max_true_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49284fb-773a-47cc-9e3d-a9ef5405ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mask_col_names = ['left_h_len', 'right_h_len', 'left_mid_ind', 'right_mid_ind', 'left_v_len', 'right_v_len']\n",
    "processed_mask_df = pd.DataFrame(\n",
    "    true_iris_df['mask_matrices'].apply(process_masks).tolist(), \n",
    "    columns=processed_mask_col_names, \n",
    "    index=true_iris_df.index\n",
    ")\n",
    "true_iris_df[processed_mask_col_names] = processed_mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101526c-6869-4804-8eb2-a47b3a93079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mask_df = pd.wide_to_long(\n",
    "    processed_mask_df.reset_index(), \n",
    "    stubnames=['left', 'right'], \n",
    "    i='index', \n",
    "    j='metric', \n",
    "    suffix='(h_len|mid_ind|v_len)', \n",
    "    sep='_'\n",
    ")\n",
    "processed_mask_df = (\n",
    "    pd.melt(processed_mask_df.reset_index(), id_vars=processed_mask_df.index.names, var_name='side')\n",
    "    .drop(columns='index')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dece600-a1b2-4f83-ad64-16a875216b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetgrid = sns.FacetGrid(processed_mask_df, col='metric', row='side', sharex=False, sharey=False, height=4, aspect=1.4)\n",
    "facetgrid.map_dataframe(sns.histplot, x='value', stat='probability', color='#019587', kde=True)\n",
    "[ax.grid(True) for ax in facetgrid.axes.flat]\n",
    "facetgrid.fig.suptitle(\"Iris masks derived distributions\", fontsize=20, y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a89cdd-f6e6-414b-a7e1-0e09d65fa1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filtered = processed_mask_df[processed_mask_df['metric'] != 'mid_ind']\n",
    "zero_mask_perc = mask_filtered.groupby(['side']).apply(lambda group: (group['value'] == 0).mean())\n",
    "zero_mask_perc.rename('Percentage of no apparent mask').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469db0db-6251-42ee-a9e1-014855bc1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_mask_df[processed_mask_df['value'] > 0 ].groupby(['side', 'metric']).agg({'mean', 'std'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79695af3-6b77-4772-9dd1-9455faa18aec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Synthethic Data Quality Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f560f9c-6af8-4d64-9aa5-002c5c8c60ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560aa55e-23d2-447f-b20f-9d8e0f2febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79cd970-c318-42fa-b63b-3ca15e914608",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbfb315-abf1-481b-b080-c09104f6e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_iris_df = pd.concat([true_iris_df.assign(source='real'), synthetic_df], ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250d520-2479-49f0-96cf-6f8799bda7b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Rotation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc08af-03df-4c45-85ee-8fa5cb971a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "for rot in range(-MAX_ROT, MAX_ROT+1): \n",
    "    if rot == 0: # No rotation - distance is 0\n",
    "        continue\n",
    "\n",
    "    all_iris_df[f'low_{rot}'], all_iris_df[f'high_{rot}'] = zip(*all_iris_df['iris_matrices'].apply(\n",
    "        lambda matrix: [np.sum(part != np.roll(part, shift=rot, axis=1)) / part.size for part in np.split(matrix, 2, axis=0)]\n",
    "    ))\n",
    "\n",
    "    # Statistical Tests\n",
    "    for (source1, group1), (source2, group2) in combinations(all_iris_df.groupby('source'), 2):\n",
    "        for wavelength in ['low', 'high']:\n",
    "            group1_wavelength = group1[f'{wavelength}_{rot}']\n",
    "            group2_wavelength = group2[f'{wavelength}_{rot}']\n",
    "\n",
    "            ks_stat, ks_p_value = ks_2samp(group1_wavelength, group2_wavelength) # Kolmogorov-Smirnov test\n",
    "            t_stat, t_p_value = ttest_ind(group1_wavelength, group2_wavelength) # Student's t test\n",
    "            \n",
    "            # Store the results in a list (you can store anything you want here)\n",
    "            results.append({\n",
    "                'Rotation':rot,\n",
    "                'wavelength':wavelength,\n",
    "                'first_source':source1,\n",
    "                'second_source':source2,\n",
    "                'ks_stat':ks_stat,\n",
    "                't_stat':t_stat,\n",
    "                'ks_p_value':ks_p_value,\n",
    "                't_p_value':t_p_value,\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['passed_KS_test'] = results_df['ks_p_value'] >= alpha\n",
    "results_df['passed_t_test'] = results_df['t_p_value'] >= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af089b-ae63-4f52-8c20-1145544a5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = (\n",
    "    results_df\n",
    "    .groupby(['first_source', 'second_source', 'wavelength'])[['ks_p_value', 'passed_KS_test', 't_p_value', 'passed_t_test']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "real_mask = results_df[['first_source', 'second_source']].isin(['real']).any(axis=1)\n",
    "results_df = results_df[real_mask]\n",
    "compared_method = np.where(results_df['first_source'] == 'real', results_df['second_source'], results_df['first_source'])\n",
    "results_df = (\n",
    "    results_df\n",
    "    .assign(compared_method=compared_method)\n",
    "    .drop(columns=['first_source', 'second_source'])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae00cc6-7a54-4da4-8534-97cf50d57962",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(['compared_method', 'wavelength']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e20ce9-71f9-4ae6-8c6b-177272c5a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.melt(\n",
    "    all_iris_df,\n",
    "    id_vars='source',\n",
    "    value_vars=[col for col in all_iris_df.columns if 'low_' in col or 'high_' in col],\n",
    "    var_name='wavelength_rotation',\n",
    "    value_name='Hamming Distance',\n",
    ")\n",
    "plot_df[['Wavelength', 'Rotation']] = plot_df['wavelength_rotation'].str.split('_', expand=True)\n",
    "plot_df.drop(columns=['wavelength_rotation'], inplace=True)\n",
    "plot_df['Rotation'] = plot_df['Rotation'].astype(int)\n",
    "plot_df['Source'] = plot_df['source'] + ', ' + plot_df['Wavelength'] + ' wavelength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98f3f9-28be-4b0c-9fc8-e458ee7eac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_linear_analysis = (\n",
    "    plot_df\n",
    "    .groupby(['Rotation', 'Wavelength', 'source'])['Hamming Distance']\n",
    "    .agg({'mean', 'std'})\n",
    "    .reset_index()\n",
    ").rename(columns={'source':'Source'})\n",
    "dist_linear_analysis = pd.melt(\n",
    "    dist_linear_analysis,\n",
    "    id_vars=['Rotation', 'Wavelength', 'Source'],\n",
    "    value_vars=['std', 'mean'],\n",
    "    var_name='Metric'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1da68-c36c-443d-a918-3032c1a31806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in ['gaussian', 'voter', 'voter_bryan', 'voter_gaussian']:\n",
    "    mask = dist_linear_analysis['Source'].isin(['real']+[source])\n",
    "    facetgrid = sns.FacetGrid(dist_linear_analysis[mask], col='Metric', height=5, aspect=2, sharex=False, sharey=False)\n",
    "    facetgrid.map_dataframe(sns.lineplot, x='Rotation', y='value', hue='Wavelength', palette='husl', style='Source')\n",
    "    [(ax.grid(True), ax.legend()) for ax in facetgrid.axes.flat]\n",
    "    facetgrid.fig.suptitle(f\"Mean and Std of real and {source.replace('_', ' ')} iris samples, in relation to rotation\", fontsize=15, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add84832-fc0a-40ff-bb36-749f1ca52483",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in ['gaussian', 'voter', 'voter_gaussian', 'voter_bryan']:\n",
    "    mask = plot_df['source'].isin(['real']+[source])\n",
    "    facetgrid = sns.FacetGrid(plot_df[mask], col='Rotation', hue='Source', palette='husl', col_wrap=5, sharex=False)\n",
    "    facetgrid.map_dataframe(sns.histplot, x='Hamming Distance', stat='probability')\n",
    "    [ax.grid(True) for ax in facetgrid.axes.flat]\n",
    "    facetgrid.add_legend()\n",
    "    facetgrid.fig.suptitle(f\"Distance distribution upon rotation\\nReal irises to {source.replace('_', ' ')} distributions\", fontsize=20, y=1.03)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747151a5-b479-478d-91e2-1d4bacd3daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_iris_samples_df = all_iris_df[all_iris_df['source'] == 'real'].drop_duplicates(subset=['subject_id', 'side'])\n",
    "real_iris_samples_df['mean_bw_ratio_low'], real_iris_samples_df['mean_bw_ratio_high'] = zip(*real_iris_samples_df['iris_matrices'].apply(\n",
    "    lambda matrix: [part.mean(axis=0) for part in np.split(matrix, 2, axis=0)]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a79015-a1ed-457b-ae9d-c4da6d00c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wavelength in ['low', 'high']:\n",
    "    bw_ratio_matrix = np.column_stack(real_iris_samples_df[f'mean_bw_ratio_{wavelength}'].values)\n",
    "    mean_values = bw_ratio_matrix.mean(axis=1)\n",
    "    ci = 1.96 * bw_ratio_matrix.std(axis=1) / np.sqrt(bw_ratio_matrix.shape[1])  # 95% CI\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=range(bw_ratio_matrix.shape[0]), y=mean_values, errorbar=None, label='Mean True / False Ratio')\n",
    "    plt.fill_between(range(bw_ratio_matrix.shape[0]), mean_values - ci, mean_values + ci, color='b', alpha=0.3, label='95% CI')\n",
    "    plt.title(f\"Mean True / False Ratio, {wavelength} wavelength with 95% Confidence Interval\")\n",
    "    plt.xlabel(\"Iris matrix x-axis\")\n",
    "    plt.ylabel(\"True / False Ratio\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b54241e-3962-48c6-bc56-b80fedac1af3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Boolean Ratio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fe8d4-3d98-4dfd-b3e8-e6e732b4bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_iris_df['Boolean Ratio'] = all_iris_df['iris_matrices'].apply(lambda matrix: matrix.mean())\n",
    "stats_df = all_iris_df.groupby('source')['Boolean Ratio'].agg({'mean', 'std'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251e31c-a828-42b6-85b5-622e3b5f4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetgrid = sns.FacetGrid(all_iris_df, col='source', sharex=False, sharey=False)\n",
    "facetgrid.map_dataframe(sns.histplot, x='Boolean Ratio', stat='probability', kde=True, color='#FF7A48')\n",
    "title_template = \"Source: {col_name}\\nMean: {mean:.2f}, Std: {std:.2f}\"\n",
    "facetgrid.set_titles(col_template=\"{col_name}\")\n",
    "for ax, col_value in zip(facetgrid.axes.flat, facetgrid.col_names):\n",
    "    mean = stats_df.loc[col_value, 'mean']\n",
    "    std = stats_df.loc[col_value, 'std']\n",
    "    ax.set_title(title_template.format(col_name=col_value, mean=mean, std=std))\n",
    "    ax.grid(True)\n",
    "facetgrid.fig.suptitle(f\"True / False Ratio Validation\", fontsize=20, y=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a98c5-c0e7-4df7-a77d-1bda025d97d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nearest to Random Dist Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ff6d5-f674-42d4-8901-a125c0753377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_rotated_matrices(matrices, max_rotation):\n",
    "    return np.vstack([\n",
    "        np.roll(matrix, shift, axis=0).flatten()\n",
    "        for matrix in matrices\n",
    "        for shift in range(-max_rotation, max_rotation + 1)\n",
    "    ])\n",
    "\n",
    "def get_min_and_random_dist_across_rotations(iris_matrices, mask_matrices, max_rotation):\n",
    "    num_matrices = len(iris_matrices)\n",
    "    num_rotations = 2 * max_rotation + 1\n",
    "\n",
    "    # Rotate matrices and masks, reshape to (num_matrices, num_rotations, flattened_size)\n",
    "    rotated_matrices = stack_rotated_matrices(iris_matrices, max_rotation).reshape(num_matrices, num_rotations, -1)\n",
    "    rotated_masks = stack_rotated_matrices(mask_matrices, max_rotation).reshape(num_matrices, num_rotations, -1)\n",
    "\n",
    "    closest_distances, random_distances = [], []\n",
    "    for i in range(num_matrices):\n",
    "        # Current matrix rotations and masks\n",
    "        current_rotated_matrix = rotated_matrices[i]\n",
    "        current_rotated_mask = rotated_masks[i]\n",
    "\n",
    "        # Extract other matrices' rotations excluding the current\n",
    "        other_rotated_matrices = np.delete(rotated_matrices, i, axis=0).reshape(-1, rotated_matrices.shape[-1])\n",
    "        other_rotated_masks = np.delete(rotated_masks, i, axis=0).reshape(-1, rotated_masks.shape[-1])\n",
    "\n",
    "        # Calculate valid positions and Hamming distances\n",
    "        valid_positions = current_rotated_mask[:, None] & other_rotated_masks\n",
    "        differences = current_rotated_matrix[:, None] != other_rotated_matrices\n",
    "\n",
    "        # Calculate Hamming distances\n",
    "        hamming_distances = np.sum(differences & valid_positions, axis=-1) / np.sum(valid_positions, axis=-1)\n",
    "        \n",
    "        # Find the minimum distance and a random distance\n",
    "        closest_distances.append(np.min(hamming_distances))\n",
    "        random_distances.append(np.random.choice(hamming_distances.flatten()))\n",
    "\n",
    "    return pd.DataFrame({\"closest_dist\": closest_distances, \"random_dist\": random_distances}, index=iris_matrices.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b2ae0-0dbd-482a-b938-004ab6a3dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_iris_samples_df = all_iris_df[all_iris_df['source'] == 'real'].drop_duplicates(subset=['subject_id', 'side'])\n",
    "balanced_non_real_samples = (\n",
    "    all_iris_df[all_iris_df['source'] != 'real']\n",
    "    .groupby('source')\n",
    "    .apply(lambda group: group.sample(len(real_iris_samples_df)))\n",
    ")\n",
    "sub_iris_df = pd.concat([real_iris_samples_df, balanced_non_real_samples], ignore_index=True)\n",
    "sub_iris_df.groupby('source').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012a11e-b2a2-4a07-816d-d27be40e6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for source, group in sub_iris_df.groupby('source'):\n",
    "    results.append(get_min_and_random_dist_across_rotations(group['iris_matrices'], group['mask_matrices'], max_rotation=MAX_ROT).assign(source = source))\n",
    "results = pd.concat(results)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cb21b-c398-4731-9272-9c3d59ec3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.melt(\n",
    "    results.rename(columns={'source':'Source'}), \n",
    "    id_vars='Source', \n",
    "    value_vars=['random_dist', 'closest_dist'],\n",
    "    var_name='Distance From',\n",
    "    value_name='Hamming Distance'\n",
    ")\n",
    "plot_df['Distance From'] = plot_df['Distance From'].apply(lambda x: x.split('_')[0].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfdde2-a382-43c6-81e1-cf16c8123b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetgrid = sns.FacetGrid(plot_df, col='Distance From', hue='Source', palette='husl', height=4, aspect=2, sharex=False, sharey=False)\n",
    "facetgrid.map_dataframe(sns.histplot, x='Hamming Distance', stat='probability', kde=True)\n",
    "[ax.grid(True) for ax in facetgrid.axes.flat]\n",
    "facetgrid.add_legend()\n",
    "facetgrid.fig.suptitle(f\"Distance from Random / Nearest iris, by data source\", fontsize=20, y=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32222ce9-4477-4738-8374-54dade3d2ff0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Comparing pair-wise distance distributions (to Daugman survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb42c5b-e45f-4eb8-9e06-f1299356d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_real_iris_samples = all_iris_df[all_iris_df['source'] != 'real']\n",
    "real_iris_samples_df = all_iris_df[all_iris_df['source'] == 'real'].drop_duplicates(subset=['subject_id', 'side'])\n",
    "sub_iris_df = pd.concat([non_real_iris_samples, real_iris_samples_df], ignore_index=True)\n",
    "sub_iris_df.groupby('source').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbf490-d8b7-4fa1-86c1-a0b9461ffc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_dist_vector(iris_matrices):\n",
    "    reshaped_matrices = np.stack(iris_matrices.values).reshape(len(iris_matrices),-1)\n",
    "    neq_matrices = np.expand_dims(reshaped_matrices, axis=1) != np.expand_dims(reshaped_matrices, axis=0)\n",
    "    dist_vector = (np.sum(neq_matrices, axis=2) / reshaped_matrices.shape[1]).flatten()\n",
    "    return dist_vector[dist_vector > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb0014-b4de-417d-b1dc-e335e74fa566",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_series = sub_iris_df.groupby('source').apply(lambda group: get_pairwise_dist_vector(group['iris_matrices']))\n",
    "sources = np.repeat(distances_series.index.values, distances_series.str.len())\n",
    "distances = np.concatenate(distances_series.values)\n",
    "plot_df = pd.DataFrame({'Source': sources, 'Distances': distances})\n",
    "plot_df = (\n",
    "    plot_df\n",
    "    .groupby('Source', group_keys=False)\n",
    "    .apply(lambda group: group.sample((plot_df['Source'] == 'real').sum()))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262fb85-fede-41ad-bf10-4e7c23ea2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(plot_df, x='Distances', stat='probability', hue='Source', palette='husl', kde=True)\n",
    "plt.grid(True)\n",
    "plt.title('Pairwise Distance Distribution', fontsize=15, y=1.07)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377dc8c-385e-49f3-894f-6341fa08f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = plot_df.groupby('Source')['Distances'].agg({'mean', 'std'})\n",
    "stats_df['N'] = (stats_df['mean'] * (1 - stats_df['mean'])) / stats_df['std']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb54d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetgrid = sns.FacetGrid(plot_df, col='Source', sharex=False, sharey=False)\n",
    "facetgrid.map_dataframe(sns.histplot, x='Distances', stat='probability', kde=True, color='#FF7A48')\n",
    "title_template = \"Source: {col_name}\\nMean: {mean:.2f}, Std: {std:.2f}, N: {N:.0f}\"\n",
    "facetgrid.set_titles(col_template=\"{col_name}\")\n",
    "for ax, col_value in zip(facetgrid.axes.flat, facetgrid.col_names):\n",
    "    mean, std, N = stats_df.loc[col_value, ['mean', 'std', 'N']] \n",
    "    ax.set_title(title_template.format(col_name=col_value, mean=mean, std=std, N=N))\n",
    "    ax.grid(True)\n",
    "facetgrid.fig.suptitle(f\"Pairwise Distance Distribution\\nStats from Daugman survey - Mean: 0.499, Std: 0.0317, N=249\", fontsize=20, y=1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbf97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af1d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc75023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18e389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
