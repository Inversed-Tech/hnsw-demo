{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab4768f-4908-4c10-a488-b640c19c6689",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1774b25c-cca7-4446-9295-601fb734b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b431268-b155-4c52-86a9-bbb87012b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnsw\n",
    "from iris.io.dataclasses import IrisTemplate\n",
    "from iris_integration import (\n",
    "    irisint_make_query as make_query,\n",
    "    irisint_query_to_vector as query_to_vector,\n",
    "    irisint_distance as distance,\n",
    "    _np_to_bigint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6175c1-a5af-4370-84ad-61b103f29878",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4 # Fit to CPU\n",
    "DIM = (2, 32, 200)\n",
    "X, Y = DIM [1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48103f77-a955-430a-b5a8-fca7fa07428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 16\n",
    "efConstruction = 128\n",
    "db_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7d62e-509d-4174-87b2-8e44d1ca3c5f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b808a1-fd4f-4e63-a092-697152898905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_array_to_iris_df(numpy_array):\n",
    "    def create_iris_template(matrix, mask):\n",
    "        return IrisTemplate(\n",
    "            iris_codes=matrix,\n",
    "            mask_codes=mask, \n",
    "            # iris_code_version=\"v3.0\" # Doesn't work on open-iris==1.0.0\n",
    "        )\n",
    "    mask = [np.ones(DIM[1:], dtype=np.bool_) for _ in range(DIM[0])]\n",
    "    iris_templates = Parallel(n_jobs=n_jobs)(delayed(create_iris_template)(list(matrix), mask) for matrix in numpy_array)\n",
    "    return pd.DataFrame({'Template': iris_templates}).assign(Inserted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd31663-f2c2-48be-a4af-c03dd758efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_voter_model_rust_implementation(path_low, path_high, total_num_samples, num_samples=None):\n",
    "    num_samples = num_samples if num_samples else total_num_samples\n",
    "    assert num_samples <= total_num_samples\n",
    "    low_high_data_lst = [\n",
    "        np.unpackbits(np.fromfile(path, dtype=np.uint8), bitorder=\"little\")\n",
    "        .reshape(total_num_samples, X, Y)\n",
    "        [np.random.choice(total_num_samples, size=num_samples, replace=False)] for path in [path_low, path_high]\n",
    "    ]\n",
    "    data = np.stack(low_high_data_lst, axis=1).astype(bool)\n",
    "    return numpy_array_to_iris_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eed4c0b-49cc-4a30-b2ee-31996527c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db(db, iris_df, db_size):\n",
    "    db_current_size = db.get_stats()['db_size']\n",
    "    assert (db_size - db_current_size) > 0\n",
    "    \n",
    "    new_irises = iris_df.loc[range(db_current_size, db_size), 'Template']\n",
    "    for iris in new_irises:\n",
    "        db.insert(make_query(iris))\n",
    "    iris_df.loc[range(db_current_size, db_size), 'Inserted'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd9901-9526-4ce0-a363-89c18b2b1a66",
   "metadata": {},
   "source": [
    "# Try-outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad386b40-f14b-4652-9089-9c4bd9a05b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_db = hnsw.HNSW(\n",
    "    M=M, \n",
    "    efConstruction=efConstruction, \n",
    "    m_L=1/np.log(M), \n",
    "    distance_func=distance, \n",
    "    query_to_vector_func=query_to_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ef79922-cb34-4cd1-bae6-15d2a94c3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_db = hnsw.HNSW(\n",
    "    M=M, \n",
    "    efConstruction=efConstruction, \n",
    "    m_L=1/np.log(M), \n",
    "    distance_func=distance, \n",
    "    query_to_vector_func=query_to_vector\n",
    ")\n",
    "iris_df = import_voter_model_rust_implementation(\n",
    "    path_low='2M_voter_arrays_80k_b45.dat', \n",
    "    path_high='2M_voter_arrays_7k_b13.dat', \n",
    "    total_num_samples=1000000, \n",
    "    num_samples=db_size\n",
    ")\n",
    "update_db(updated_db, iris_df, db_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef0d866c-7483-4961-bba4-dca789c15744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute 'entry_point' has changed.\n",
      "Attribute 'layers' has changed.\n",
      "Attribute 'lock' has changed.\n",
      "Attribute 'n_comparisons' has changed.\n",
      "Attribute 'n_distances' has changed.\n",
      "Attribute 'n_improve' has changed.\n",
      "Attribute 'n_insertions' has changed.\n",
      "Attribute 'stat_time' has changed.\n",
      "Attribute 'vectors' has changed.\n"
     ]
    }
   ],
   "source": [
    "for attribute in dir(empty_db):\n",
    "    if not attribute.startswith('__'):\n",
    "        new_value = getattr(empty_db, attribute)\n",
    "        if callable(new_value):\n",
    "            continue\n",
    "        processed_value = getattr(updated_db, attribute)\n",
    "        if new_value != processed_value:\n",
    "            print(f\"Attribute '{attribute}' has changed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3a8b4-11c2-4f9c-aef8-ae1886c9302e",
   "metadata": {},
   "source": [
    "# Code Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a33bf7-9334-41b1-b4aa-b6cf525306c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_to_dict(input_string):\n",
    "    try:\n",
    "        parsed_dict = json.loads(input_string)\n",
    "        return parsed_dict\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing string: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_entry_point(db, entries):\n",
    "    db.entry_point[:] = entries['id'].values.tolist()\n",
    "\n",
    "def update_n_insertions(db, vectors):\n",
    "    db.n_insertions = len(vectors)\n",
    "\n",
    "def update_layers(db, links):\n",
    "    def process_links(df):\n",
    "        def process_row(row):\n",
    "            return [(item[1], item[0]) for item in row['queue']]\n",
    "            \n",
    "        df['processed_queue'] = df['links'].apply(lambda x: process_row(x))\n",
    "        return pd.Series(df['processed_queue'].values, index=df['source_ref']).to_dict()\n",
    "        \n",
    "    db.layers = links.groupby('layer').apply(process_links).sort_index(ascending=True).tolist()\n",
    "\n",
    "def update_vectors(db, vectors):\n",
    "    def process_vectors(data_dict):\n",
    "        data = np.array(data_dict['data']['data'])\n",
    "        bi = np.where(data == -1, 1, 0)\n",
    "        mi = np.where(data != 0, 1, 0)\n",
    "        return (_np_to_bigint(bi.astype(np.bool_)), _np_to_bigint(mi.astype(np.bool_)))\n",
    "\n",
    "    vectors_sorted = vectors.sort_values(by='id')\n",
    "    processed_points = vectors_sorted['point'].apply(process_vectors)\n",
    "    db.vectors = processed_points.tolist()\n",
    "\n",
    "def copy_in(db, vectors, links, entries):\n",
    "    update_vectors(db, vectors)\n",
    "    update_layers(db, links)\n",
    "    update_n_insertions(db, vectors)\n",
    "    update_entry_point(db, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d41ef3c8-0c63-4573-83f4-f61df3bf00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_csv('hnsw_db_100_3896635365_vectors.csv')\n",
    "links = pd.read_csv('hnsw_db_100_141959194_hawk_graph_links.csv')\n",
    "entries = pd.read_csv('hnsw_db_100_141959194_hawk_graph_entry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d636d21f-6a31-4f7a-943d-36416e95d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "links['links'] = links['links'].apply(lambda x: parse_string_to_dict(x))\n",
    "vectors['point'] = vectors['point'].apply(lambda x: parse_string_to_dict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "941eea41-e616-4563-860f-3234f3752dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/pshnfl_53rv2t0zccy8bcr_m0000gn/T/ipykernel_2314/3661424880.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  db.layers = links.groupby('layer').apply(process_links).sort_index(ascending=True).tolist()\n"
     ]
    }
   ],
   "source": [
    "copy_in(empty_db, vectors, links, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd809a-5306-4ccf-b79b-adaf07a48b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
