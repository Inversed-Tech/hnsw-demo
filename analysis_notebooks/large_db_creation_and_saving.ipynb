{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31e448a-2aff-40fd-b721-b4f1baa07691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "# ! sudo apt install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxrender1 libxext6\n",
    "# ! pip install open-iris==1.0.0 faiss-cpu seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765202e0-2135-4dce-a4d2-fc0d3fe39f0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37203805-61d2-4963-bd9e-dd32f226ef24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d241ba67-e0cc-46b6-a63d-8549e7ba9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from io import BytesIO\n",
    "from itertools import combinations, product\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06ce7e7-20b8-46a6-a236-3ef55eee4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from scipy.spatial.distance import hamming\n",
    "from scipy.stats import ks_2samp, ttest_ind\n",
    "from threading import Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6254887e-aa35-4657-b4b3-25bcfb572efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnsw\n",
    "from iris.io.dataclasses import IrisTemplate\n",
    "from iris_integration import (\n",
    "    iris_with_noise,\n",
    "    irisint_make_query as make_query,\n",
    "    irisint_query_to_vector as query_to_vector,\n",
    "    irisint_distance as distance,\n",
    "    int_distance\n",
    ")\n",
    "from iris_pairwise_min_dist_calculation import get_pairwise_min_dist_across_rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4c645f-001c-46a7-82ed-48b5e28b771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 6 # Fit to CPU\n",
    "DIM = (2, 32, 200)\n",
    "base_path = 'db/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a87c9-389d-4af7-8e91-e73678ed0146",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f3160b-b577-40da-a6af-9940a8c958b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update_time = time.time()\n",
    "def print_progress(msg, delay=1, force_print=False):\n",
    "    global last_update_time\n",
    "    if (time.time() - last_update_time > delay) or force_print:\n",
    "        sys.stdout.write('\\r' + ' ' * 200)\n",
    "        sys.stdout.write(f\"\\r{msg}\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        last_update_time = time.time()\n",
    "\n",
    "def save_pickle(obj, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    print(f\"Object successfully saved to {filename}\")\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        obj = pickle.load(file)\n",
    "    print(f\"Object successfully loaded from {filename}\")\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c680e91b-9672-4dd7-b93d-305dbb7a27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boolean_iris(matrix, title=''):\n",
    "    plt.imshow(matrix, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9489853f-1160-4379-9c75-57414d926109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_scaled_string(n):\n",
    "    suffixes = ['', 'K', 'M', 'B', 'T']\n",
    "    idx = max(0, min(len(suffixes) - 1, int((len(str(abs(n))) - 1) / 3)))\n",
    "    scaled = n / (1000 ** idx)\n",
    "    return f\"{scaled:.1f}{suffixes[idx]}\" if scaled % 1 else f\"{int(scaled)}{suffixes[idx]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162f8ea-4648-4370-92fd-1f3478f6138f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0badda9-84e3-4283-80b9-d8dfb51a2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_partial_file(filename, num_bits):\n",
    "    num_bytes = (num_bits + 7) // 8  # Ensure we round up if num_bits isn't a multiple of 8\n",
    "    with open(filename, 'rb') as f:\n",
    "        chunk = f.read(num_bytes)\n",
    "    return np.frombuffer(chunk, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2342bab4-e456-4757-858f-9471313f2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_reshape_masks(filename, num_masks, DIM=DIM):\n",
    "    flattened_data = np.unpackbits(read_partial_file(filename, ((DIM[1]//2) * DIM[2]) * num_masks))\n",
    "    boolean_arrays = flattened_data.reshape((num_masks, DIM[1]//2, DIM[2]))\n",
    "    vertically_stacked = np.tile(boolean_arrays, (1, 2, 1))\n",
    "    duplicated_arrays = np.repeat(vertically_stacked[:, np.newaxis, :, :], DIM[0], axis=1)\n",
    "    return duplicated_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614f337b-cdc2-4ef5-968b-754228da81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_reshape_irises(path_low, path_high, num_samples, DIM=DIM):\n",
    "    low_high_lst = [\n",
    "        np.unpackbits(\n",
    "            read_partial_file(path, (reduce(mul, DIM[1:]) * num_samples)), bitorder=\"little\"\n",
    "        ).reshape(num_samples, *DIM[1:]) for path in [path_low, path_high]\n",
    "    ]\n",
    "    return np.concatenate(low_high_lst, axis=1).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7759adc-0a87-4986-befa-de555ae2ea55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test Functions and DB Buildup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beebdb36-f7ed-4f3e-9007-95780ef33cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db(db, iris_df, db_size, force_layer=None):\n",
    "    db_current_size = db.get_stats()['db_size']\n",
    "    if (db_size - db_current_size) <= 0:\n",
    "        return\n",
    "    \n",
    "    new_irises = iris_df.loc[range(db_current_size, db_size), 'Template']\n",
    "    for i, iris in enumerate(new_irises):\n",
    "        print_progress(f'Currently building {int_to_scaled_string(db_size)} DB, M={db.M}, with efConstruction={db.efConstruction}. Insertion Progress: {(i+1)/len(new_irises):.1%}')\n",
    "        db.insert(make_query(iris), insert_layer=force_layer)\n",
    "    iris_df.loc[range(db_current_size, db_size), 'Inserted'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4683a45-580c-486c-bc82-d8393015b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_array_to_iris_df(iris_array, mask_array):\n",
    "    def create_iris_template(matrix, mask):\n",
    "        return IrisTemplate(\n",
    "            iris_codes=matrix,\n",
    "            mask_codes=mask, \n",
    "            # iris_code_version=\"v3.0\" # Doesn't work on open-iris==1.0.0\n",
    "        )\n",
    "    iris_templates = Parallel(n_jobs=n_jobs)(delayed(create_iris_template)(list(iris), list(mask)) for iris, mask in zip(iris_array, mask_array))\n",
    "    return pd.DataFrame({'Template': iris_templates}).assign(Inserted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198d877-10bd-4d79-9703-36c27e064069",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712eda6-b866-4f08-af01-d74343f37f6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f03f6a1-bd95-4f90-8578-47002f867e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_size = 2**22\n",
    "max_tested_db_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e6f68de-3556-42bb-b50f-ef7915b31af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_masks = f'synthetic_data/{int_to_scaled_string(synthetic_data_size)}_mask_arrays.dat'\n",
    "path_iris_low = 'synthetic_data/2_23_voter_arrays_90k_b090.dat'\n",
    "path_iris_high = 'synthetic_data/2_23_voter_arrays_14k_b010.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905d802-1a21-4a60-a039-c86f2cba21bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "593e55bf-6f71-4362-a412-83d76e8b1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_masks = load_and_reshape_masks(path_masks, max_tested_db_size).astype(bool)\n",
    "loaded_irises = load_and_reshape_irises(path_iris_low, path_iris_high, max_tested_db_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e653a08-4e76-4ce5-8ce4-0eeb220018df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reassuring stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890b40b4-2d15-408d-986a-772b9436dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly loaded 100 masks and irises\n"
     ]
    }
   ],
   "source": [
    "assert len(loaded_masks) == max_tested_db_size\n",
    "assert len(loaded_irises) == max_tested_db_size\n",
    "print(f'Successfuly loaded {int_to_scaled_string(max_tested_db_size)} masks and irises')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f1c37-d789-421d-b06c-91e10ffa5bd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DB Creation and Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f99e9-c36b-46bf-ad94-5526dbf1c678",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c5ff548-0fb3-4ef7-b91d-3394c999a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 64\n",
    "efConstruction = 64\n",
    "db_sizes = np.arange(100000, 500001, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "499855be-c93e-469a-b16d-f3b9f0210b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert db_sizes.max() <= max_tested_db_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a470e-68ba-413b-8e04-de33b90ec40a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Build up and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2de0963-7f6c-4d7e-ac23-eaee99c670a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = numpy_array_to_iris_df(loaded_irises.reshape(max_tested_db_size, *DIM), loaded_masks)\n",
    "db = hnsw.HNSW(\n",
    "    M=M, \n",
    "    efConstruction=efConstruction, \n",
    "    m_L=1/np.log(M), \n",
    "    distance_func=distance, \n",
    "    query_to_vector_func=query_to_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d9e054e-c885-40cb-b6b3-f273d28c5e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently building 1K DB, M=64, with efConstruction=64. Insertion Progress: 97.9%                                                                                                                       Object successfully saved to db/1Kdb_M64_efConstruction64.pkl\n",
      "Currently building 2K DB, M=64, with efConstruction=64. Insertion Progress: 98.9%                                                                                                                       Object successfully saved to db/2Kdb_M64_efConstruction64.pkl\n"
     ]
    }
   ],
   "source": [
    "for db_size in db_sizes:\n",
    "    update_db(db, iris_df, db_size)\n",
    "    del db.lock\n",
    "    save_pickle(db, f'{base_path}db{int_to_scaled_string(db_size)}_M{M}_efConstruction{efConstruction}.pkl')\n",
    "    db.lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e002a-c6d9-4ed8-8632-267a968f0460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c073bff-ced7-42db-886d-3cce7ce06e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6417a8-c46b-4fb9-b3c8-72794ac73425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
